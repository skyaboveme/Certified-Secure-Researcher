# Robots.txt for Certified Secure Researcher
# https://certifiedsecureresearcher.com

User-agent: *
Allow: /

# Sitemap location
Sitemap: https://certifiedsecureresearcher.com/sitemap.xml

# Allow all major search engines and AI crawlers
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: DuckDuckBot
Allow: /

User-agent: Slurp
Allow: /

User-agent: Baiduspider
Allow: /

User-agent: YandexBot
Allow: /

# AI and LLM crawlers
User-agent: GPTBot
Allow: /

User-agent: ChatGPT-User
Allow: /

User-agent: Claude-Web
Allow: /

User-agent: Anthropic-AI
Allow: /

User-agent: PerplexityBot
Allow: /

User-agent: CCBot
Allow: /

User-agent: Google-Extended
Allow: /

# Disallow admin and private paths (none currently)
# Disallow: /admin/
# Disallow: /private/

# Cache control
# Crawl-delay: 1
